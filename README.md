# Local LLM Integration with Semantic Kernel

This project demonstrates how to integrate a locally hosted Large Language Model (LLM) running using Ollama and C# Microsoft Semantic Kernel.

## Core Technologies

### Ollama
- [Ollama GitHub Repository](https://github.com/ollama/ollama?tab=readme-ov-file#ollama)
    
    > Run large language models locally

### Microsoft Semantic Kernel
- [Official Documentation](https://learn.microsoft.com/en-us/semantic-kernel/overview/)
    
    > SDK for building AI-powered applications

## Learning Resources

- [Develop Generative AI Applications](https://learn.microsoft.com/en-us/training/paths/develop-ai-agents-azure-open-ai-semantic-kernel-sdk/)
  > Build AI agents with Azure OpenAI and Semantic Kernel

- [.NET AI Template (Preview)](https://statics.teams.cdn.office.net/evergreen-assets/safelinks/1/atp-safelinks.html)
  > Getting started template for .NET AI applications

## Cloud-Based Platforms

- [GitHub Marketplace](https://github.com/marketplace)
  > Find actions and apps for your development workflow

- [Azure AI Foundry](https://ai.azure.com/)
  > Build and deploy AI solutions on Azure

- [Hugging Face](https://huggingface.co/)
  > Repository of machine learning models and datasets

- [Hugging Face Chat](https://huggingface.co/chat/)
  > Interactive chat interface for testing language models

- [Open AI](https://platform.openai.com/docs/overview)
  > API and Platform for accessing OpenAI models

- [Mistral](https://mistral.ai)
  > API and Platform for accessing to Mistral

## Visual Studio Templates:

- [NET AI Template](https://devblogs.microsoft.com/dotnet/announcing-dotnet-ai-template-preview1/?utm_content=326721173&utm_medium=social&utm_source=linkedin&hss_channel=lcp-18055275)
  > Create AI-powered applications with .NET